# SOCO--Agentic-Chat-Agent
Soco is an interactive AI Chatbot is developed using Streamlit. The application combines Prompt Engineering, Agentic AI, Langchain , Groq API, real time Weather API and Conversational Intelligence. The Project understand the users intent and context using LLM (llama3-8b-8192), and provides conversational and reactive response to the user. 
**Features**
        ✅ Understands user intent and context using Groq API's Llama model (Llama3-8b-8192).
        ✅ Leverages LangChain for multi-step reasoning and memory retention.
        ✅ Fetches external data through APIs (e.g., real-time weather updates).
        ✅ Enhances response coherence and adaptability using Prompt Engineering.
        ✅ Intelligently decides when to call an API based on user queries.
        ✅ Utilizes LangChain memory for multi-turn conversations.
        ✅ Includes a user-friendly UI powered by Streamlit.
        
It aims to provide accurate and concise responses, adhering to user requirements like word limits and context-sensitive queries.

**Working**
The conversational AI agent leverages Groq's Llama model for generating conversational responses and integrates the Weather API for real-time weather updates for a specified city. API keys, such as the Weather API key and Groq API key, are securely stored in the .env file. Chat memory is managed using ConversationBufferMemory, enabling context-aware, multi-turn conversations.

The get_weather function uses the Weather API key and URL to fetch weather details, such as temperature and conditions. This function is utilized by the Weather Tool, which provides real-time weather updates. The agent intelligently decides between using the GroqChat tool for general queries or the Weather Tool for weather-related queries, relying on the presence of the keyword "weather" to trigger the appropriate functionality.

A structured prompt ensures that the agent responds thoughtfully, adheres to constraints like word limits, and gracefully acknowledges its limitations when necessary. The LangChain memory component, ConversationBufferMemory, stores chat history to facilitate seamless multi-turn interactions. The raw responses generated by the agent are parsed and displayed in the UI, with the chat history dynamically updating after each user query.

The Streamlit interface provides a responsive and intuitive user experience, enabling users to input queries, view agent responses, and access the conversation history effortlessly.
How users can get started with the project
1.	Clone the repository and navigate to the project directory.
2.	Set up the required dependencies using the command: 
                  pip install -r requirements.txt
3.	Create a .env file in the project directory and add your API keys:
    o	GROQ_API_KEY: Your Groq API key.
    o	weather_api: Your Weather API key.
4.	Run the Streamlit application with the command:
                 streamlit run app.py
5.	Use the web interface to input queries and interact with the chatbot.


The project is maintained by C Steffi Angel with contributions from the open-source community. Contributions are welcome, and users can contribute by submitting pull requests, reporting bugs, or suggesting new features through the GitHub repository.
